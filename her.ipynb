{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindsight Experience Replay\n",
    "\n",
    "This notebook explores an old RL algorithm called Hindsight Experience Replay (HER) for solving the click problem of click agents. The core intuition behind HER centers on agents learning from every action. The result of each movement, even if unsuccessful, can be retroactively seen as the goal.\n",
    "\n",
    "Algorithm:\n",
    "* The agent generates a set of targets to click based on the current screenshot.\n",
    "* For each target, the agent retrieves the current mouse coordinates and generates (Δx, Δy) to move the mouse to the target.\n",
    "* The agent takes another screenshot and looks to see if the cursor is a pointer or an arrow, as well as if the cursor is over the target.\n",
    "  * If the cursor is a pointer, but the agent is not over the target, the agent generates a description of the current location and uses that to create a new completed target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentdesk import Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = Desktop.gce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Location\n",
    "\n",
    "Describe the current location of the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from mllm import Router, RoleThread\n",
    "from surfninja.img import b64_to_image, image_to_b64, crop_box_around\n",
    "\n",
    "router = Router.from_env()\n",
    "\n",
    "class ClickArea(BaseModel):\n",
    "    purpose: str = Field(description=\"Purpose of the the element the cursor is over e.g. to login the user\")\n",
    "    description: str = Field(description=\"Description of what the mouse cursor is over\")\n",
    "    location: str = Field(description=\"General location of the mouse cursor relative to the full screen, e.g. top left, bottom right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_location(desktop: Desktop) -> ClickArea:\n",
    "    \"\"\"Describe the current location of the mouse\"\"\"\n",
    "    \n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I'm going to provide you with two images. The first is a picture of a desktop UI, \n",
    "    the second is a cropped portion of the first image containing just a 100x100 portion focusing on where the mouse cursor is.\n",
    "    Please describe what the mouse cursor as a JSON object conforming to the schema {ClickArea.model_json_schema()}.\n",
    "    Please return just raw json. For example if you see the mouse above the chromium icon then \n",
    "    you would return {{\"is_clickable\": true, \"description\": \"A blue chromium icon with the text 'chromium' beneath it\", \"location\": \"top-right\"}}.\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(cropped)],\n",
    "    )\n",
    "\n",
    "    resp = router.chat(thread, expect=ClickArea)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Targets\n",
    "\n",
    "Identify all possible clickable targets on a screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Target(BaseModel):\n",
    "    \"\"\"A target which the mouse could be moved to\"\"\"\n",
    "    \n",
    "    description: str = Field(description=\"A long description of the target e.g. A round blue button with the text 'login'\")\n",
    "    location: str = Field(description=\"A general location of the target e.g. top-right, center, bottom-left\")\n",
    "    purpose: str = Field(description=\"A general purpose of the target e.g. login, logout, register\")\n",
    "\n",
    "class Targets(BaseModel):\n",
    "    targets: List[Target] = Field(description=\"A list of targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(desktop: Desktop) -> Targets:\n",
    "    \"\"\"Generate targets from a desktop screenshot\"\"\"\n",
    "    \n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with an image of a desktop UI. Please describe all the possible targets that you can interact with.\n",
    "    Please return a JSON object that conforms to the schema {Targets.model_json_schema()}.\n",
    "    Please be exhaustive, describing all possibilities on the screenshot.\n",
    "    Please return just raw json. For example {{\"targets\": [{{\"description\": \"A green button resembling a user\", \"location\": \"top-left\", \"purpose\": \"open user settings\"}}]}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=Targets)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to Targets\n",
    "Navigate to a target description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveDirection(BaseModel):\n",
    "    x: int = Field(description=\"Amount to move in the x direction. Positive values move right, negative values move left. 1 is equal to 1 pixel.\")\n",
    "    y: int = Field(description=\"Amount to move in the y direction. Positive values move down, negative values move up. 1 is equal to 1 pixel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_move_direction(desktop: Desktop, target: Target) -> MoveDirection:\n",
    "    \"\"\"Generate the next direction to move the mouse (Δx, Δy)\"\"\"\n",
    "\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images: a screenshot of a desktop UI, and a cropped 100x100 image of the current mouse location. \n",
    "    Your goal is to navigate to '{target.description}' located in '{target.location}'. The screen size is {img.size} and the current coordinates are {coords}. \n",
    "    Please tell me which direction to move the mouse to get there. Please return a JSON object which conforms to the schema {MoveDirection.model_json_schema()}.\n",
    "    Please return raw json. For example, if I want to move 12 pixels to the left, and 3 pixels up, I would return: {{ \"x\": -12, \"y\": 3}}. You must move the mouse, \n",
    "    either 'x' or 'y' must be non-zero. The very tip of the cursor must be on your desired target, if unsure, move the mouse slightly.\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(cropped)]\n",
    "    )\n",
    "    img.save(\"./.run/screenshot_move.png\")\n",
    "    cropped.save(\"./.run/cropped_move.png\")\n",
    "    resp = router.chat(thread, expect=MoveDirection)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "\n",
    "def apply_move(desktop: Desktop, direction: MoveDirection) -> Tuple[Image.Image, Image.Image]:\n",
    "    \"\"\"Apply a mouse movement to the desktop\"\"\"\n",
    "    \n",
    "    current_coords = desktop.mouse_coordinates()\n",
    "    print(\"current_cords: \", current_coords)\n",
    "\n",
    "    # Calculate new absolute mouse coordinates\n",
    "    new_x = current_coords[0] + direction.x\n",
    "    new_y = current_coords[1] + direction.y\n",
    "\n",
    "    print(\"new: \", new_x, new_y)\n",
    "\n",
    "    # Move the mouse to the new coordinates\n",
    "    desktop.move_mouse(x=new_x, y=new_y)\n",
    "\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "    print(\"new_coords: \", coords)\n",
    "\n",
    "    return img, cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CursorType(BaseModel):\n",
    "    type: str = Field(description=\"Can be 'default', 'text', or 'pointer'\")\n",
    "\n",
    "\n",
    "def det_cursor_type(desktop: Desktop) -> CursorType:\n",
    "    \"\"\"Detect the cursor type\"\"\"\n",
    "\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1], padding=30)\n",
    "\n",
    "    cropped.save(\"./.run/cursor.png\")\n",
    "\n",
    "    composite = Image.open(\"./assets/cursor_composite_image.jpg\")\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images; first is an image of a mouse cursor and the second is an image \n",
    "        displaying the different types of cursors and their names. Please return what type of cursor you see.\n",
    "        Please return a json object which conforms to the schema {CursorType.model_json_schema()}.\n",
    "        Please return just raw json. For example if the cursor looks like a standard pointer return {{\"type\": \"default\"}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(cropped), image_to_b64(composite)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=CursorType)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed\n",
    "\n",
    "\n",
    "class CheckGoal(BaseModel):\n",
    "    done: bool = Field(description=\"Whether the cursor is over the correct location\")\n",
    "\n",
    "\n",
    "def is_finished(desktop: Desktop, target: Target) -> bool:\n",
    "    \"\"\"Check if the target has been reached\"\"\"\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images: a screenshot of a desktop UI, and a cropped 100x100 image of the current mouse location. \n",
    "    Your goal is to navigate to '{target.description}' located in '{target.location}'. The screen size is {img.size} and the current coordinates are {coords}. \n",
    "    Please tell me if we have achieved that goal. Please return your response as a JSON object which conforms to the schema {CheckGoal.model_json_schema()}.\n",
    "    Please return raw json. If the goal is achieved the cursor should be directly over the target and should be a pointer, then return {{\"done\": true}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(cropped)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=CheckGoal)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed.done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets(desktop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = targets.targets[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.open_url(\"https://google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger(\"mllm.router\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.DEBUG)  # Ensuring the handler captures debug logs\n",
    "\n",
    "# Optionally add a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(stdout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 10\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "shutil.rmtree(\"./.run\")\n",
    "os.makedirs(\"./.run\")\n",
    "\n",
    "completed_targets: List[Target] = []\n",
    "\n",
    "\n",
    "for step in range(max_steps):\n",
    "    print(\"\\n---- checking if task is finished...\")\n",
    "    cursor_type = det_cursor_type(desktop)\n",
    "\n",
    "    print(\"cursor type: \", cursor_type.type)\n",
    "    if cursor_type.type != \"default\":\n",
    "        if is_finished(desktop, target):\n",
    "            print(\"task is done\")\n",
    "            completed_targets.append(target)\n",
    "            break\n",
    "\n",
    "        print(\"task is not finished but cursor is not default\")\n",
    "        area = describe_location(desktop)\n",
    "        target = Target(description=area.description, location=area.location, purpose=area.purpose)\n",
    "        completed_targets.append(target)\n",
    "        print(\"area: \", area.model_dump())\n",
    "\n",
    "        \n",
    "    print(\"\\n---- step: \", step)\n",
    "    direct = get_move_direction(desktop, target)\n",
    "\n",
    "    print(\"\\n---- move direction: \", direct.model_dump())\n",
    "\n",
    "    new_screen, new_cursor = apply_move(desktop, direct)\n",
    "    new_screen.save(\"./.run/step_\" + str(step) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
