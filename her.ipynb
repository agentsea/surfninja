{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindsight Experience Replay\n",
    "\n",
    "This notebook explores an old RL algorithm called Hindsight Experience Replay (HER) for solving the problem of clicking on GUI elements. The core intuition behind HER centers on agents learning from every action. The result of each movement, even if unsuccessful, can be retroactively seen as the goal. We borrow from ideas of self-supervision to bring HER into generative agents.\n",
    "\n",
    "Algorithm:\n",
    "* The agent generates a set of targets to click based on the current screenshot.\n",
    "* For each target, the agent retrieves the current mouse coordinates and generates (Δx, Δy) to move the mouse to the target.\n",
    "* The agent takes another screenshot and looks to see if the cursor is a pointer or an arrow, as well as if the cursor is over the target.\n",
    "  * If the cursor is a pointer, but the agent is not over the target, the agent generates a description of the current location and uses that to create a new completed target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentdesk import Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = Desktop.gce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upscale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import replicate\n",
    "\n",
    "def upscale_image(img: Image.Image, scale: int = 4) -> str:\n",
    "\n",
    "    # Convert the PIL image to bytes\n",
    "    image_bytes = io.BytesIO()\n",
    "    img.save(image_bytes, format='JPEG')\n",
    "    image_bytes.seek(0)\n",
    "\n",
    "    # Run the replicate model\n",
    "    output = replicate.run(\n",
    "        \"nightmareai/real-esrgan:350d32041630ffbe63c8352783a26d94126809164e54085352f8326e53999085\",\n",
    "        input={\n",
    "            \"image\": image_bytes,\n",
    "            \"scale\": scale,\n",
    "            \"face_enhance\": False\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return output  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Location\n",
    "\n",
    "Describe the current location of the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from mllm import Router, RoleThread\n",
    "from surfninja.img import b64_to_image, image_to_b64, crop_box_around\n",
    "router = Router.from_env()\n",
    "\n",
    "from typing import List\n",
    "\n",
    "class ClickTarget(BaseModel):\n",
    "    \"\"\"A target which the mouse could be moved to and clicked\"\"\"\n",
    "    \n",
    "    description: str = Field(description=\"A long description of the target e.g. A round blue button with the text 'login'\")\n",
    "    location: str = Field(description=\"A general location of the target e.g. top-right, center, bottom-left\")\n",
    "    purpose: str = Field(description=\"A general purpose of the target e.g. 'log the user in' or 'search for a product'\")\n",
    "    expectation: str = Field(description=\"An expectation on what will happen when you click this target e.g. 'A login screen will appear'\")\n",
    "\n",
    "class ClickTargets(BaseModel):\n",
    "    targets: List[ClickTarget] = Field(description=\"A list of click targets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_location(desktop: Desktop) -> ClickTarget:\n",
    "    \"\"\"Describe the current location of the mouse\"\"\"\n",
    "    \n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I'm going to provide you with two images. The first is a picture of a desktop UI, \n",
    "    the second is a cropped portion of the first image containing just a 100x100 portion focusing on where the mouse cursor is.\n",
    "    Please describe what the mouse cursor as a JSON object conforming to the schema {ClickTarget.model_json_schema()}.\n",
    "    Please return just raw json. For example if you see the mouse above the chromium icon then \n",
    "    you would return {{\"is_clickable\": true, \"description\": \"A blue chromium icon with the text 'chromium' beneath it\", \"location\": \"top-right\"}}.\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(cropped)],\n",
    "    )\n",
    "\n",
    "    resp = router.chat(thread, expect=ClickTarget)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Targets\n",
    "\n",
    "Identify all possible clickable targets on a screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(desktop: Desktop) -> ClickTargets:\n",
    "    \"\"\"Generate targets from a desktop screenshot\"\"\"\n",
    "    \n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with an image of a desktop UI. Please describe all the possible targets that you can interact with.\n",
    "    Please return a JSON object that conforms to the schema {ClickTargets.model_json_schema()}.\n",
    "    Please be exhaustive, describing all possibilities on the screenshot.\n",
    "    Please return just raw json. For example {{\"targets\": [{{\"description\": \"A green button resembling a user\", \"location\": \"top-left\", \"purpose\": \"open user settings\"}}]}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=ClickTargets)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to Targets\n",
    "Navigate to a target description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveDirection(BaseModel):\n",
    "    current_location: str = Field(description=\"A description of the current location of the mouse cursor e.g. 'The cursor is currently over a red button in the bottom right of the image'\")\n",
    "    reason: str = Field(description=\"Why the move was made e.g. 'The mouse cursor is in the center of the image but the target is in the top left, I need to move up and to the left'\")\n",
    "    x: int = Field(description=\"Amount to move in the x direction. Positive values move right, negative values move left. 1 is equal to 1 pixel.\")\n",
    "    y: int = Field(description=\"Amount to move in the y direction. Positive values move down, negative values move up. 1 is equal to 1 pixel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_move_direction(desktop: Desktop, target: ClickTarget) -> MoveDirection:\n",
    "    \"\"\"Generate the next direction to move the mouse (Δx, Δy)\"\"\"\n",
    "\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1], 100)\n",
    "\n",
    "    upscaled = upscale_image(cropped, 4)\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images: a screenshot of a desktop UI, and a cropped 200x200 image of the current mouse location. \n",
    "    Your goal is to navigate to '{target.description}' located in '{target.location}'. The screen size is {img.size} and the current coordinates are {coords}. \n",
    "    Please tell me which direction to move the mouse to get there. Please return a JSON object which conforms to the schema {MoveDirection.model_json_schema()}.\n",
    "    Please return raw json. For example, if I want to move 12 pixels to the left, and 3 pixels up, I would return: \n",
    "    {{\"reason\": \"The mouse is slightly below the current object and a bit to the right. I need to move the mouse up and to the left\", \"x\": -12, \"y\": -3}}. You must move the mouse, \n",
    "    either 'x' or 'y' must be non-zero. The very tip of the cursor must directly over the center your desired target, if unsure, move the mouse slightly.\n",
    "    YOU MUST MOVE THE MOUSE, it has already been determined that you are not in the correct location, double check that you are directly over the target, not just near it.\n",
    "    The cursor will likely change to a pointer if you are over it.\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(upscaled)]\n",
    "    )\n",
    "    img.save(\"./.run/screenshot_move.png\")\n",
    "    cropped.save(\"./.run/cropped_move.png\")\n",
    "    resp = router.chat(thread, expect=MoveDirection)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "\n",
    "def apply_move(desktop: Desktop, direction: MoveDirection) -> Tuple[Image.Image, Image.Image]:\n",
    "    \"\"\"Apply a mouse movement to the desktop\"\"\"\n",
    "    \n",
    "    current_coords = desktop.mouse_coordinates()\n",
    "    print(\"current_cords: \", current_coords)\n",
    "\n",
    "    # Calculate new absolute mouse coordinates\n",
    "    new_x = current_coords[0] + direction.x\n",
    "    new_y = current_coords[1] + direction.y\n",
    "\n",
    "    print(\"new: \", new_x, new_y)\n",
    "\n",
    "    if new_x == 0 and new_y == 0:\n",
    "        # Bugs happen at (0, 0)\n",
    "        new_x = 1\n",
    "        new_y = 1\n",
    "\n",
    "    # Move the mouse to the new coordinates\n",
    "    desktop.move_mouse(x=new_x, y=new_y)\n",
    "\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "    print(\"new_coords: \", coords)\n",
    "\n",
    "    return img, cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def draw_red_box(image: Image.Image, point: Tuple[int, int], padding: int) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Draw a red box around a point in an image using padding.\n",
    "\n",
    "    :param image_path: Path to the input image\n",
    "    :param point: Tuple (x, y) indicating the center of the box\n",
    "    :param padding: Padding around the point to determine the box size\n",
    "    \"\"\"\n",
    "    # Open the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Calculate the box coordinates using padding\n",
    "    left = point[0] - padding\n",
    "    top = point[1] - padding\n",
    "    right = point[0] + padding\n",
    "    bottom = point[1] + padding\n",
    "    \n",
    "    # Draw the red box\n",
    "    draw.rectangle([left, top, right, bottom], outline=\"red\", width=3)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CursorType(BaseModel):\n",
    "    type: str = Field(description=\"Can be 'default', 'text', or 'pointer'\")\n",
    "\n",
    "\n",
    "def det_cursor_type(desktop: Desktop) -> CursorType:\n",
    "    \"\"\"Detect the cursor type\"\"\"\n",
    "\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1], padding=30)\n",
    "\n",
    "    cropped.save(\"./.run/cursor.png\")\n",
    "\n",
    "    composite = Image.open(\"./assets/cursor_composite_image.jpg\")\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images; first is an image of a mouse cursor and the second is an image \n",
    "        displaying the different types of cursors and their names. Please return what type of cursor you see.\n",
    "        Please return a json object which conforms to the schema {CursorType.model_json_schema()}.\n",
    "        Please return just raw json. For example if the cursor looks like a standard pointer return {{\"type\": \"default\"}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(cropped), image_to_b64(composite)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=CursorType)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed\n",
    "\n",
    "\n",
    "class CheckGoal(BaseModel):\n",
    "    target: str = Field(description=\"Description of the click target in your own words e.g. 'blue_button'\")\n",
    "    current_location: str = Field(description=\"A description of the current location of the mouse cursor e.g. 'The mouse curesor is currently over a blue button in the bottom-left of the image'\")\n",
    "    reason: str = Field(description=\"Reasoning as to whether the cursor is over the correct location e.g. 'The cursor is over a blue button in the bottom-left but needs to be over a red button in the top-right, task is not complete'\")\n",
    "    done: bool = Field(description=\"Whether the cursor is over the correct location\")\n",
    "\n",
    "\n",
    "def is_finished(desktop: Desktop, target: ClickTarget) -> bool:\n",
    "    \"\"\"Check if the target has been reached\"\"\"\n",
    "    \n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1], 100)\n",
    "\n",
    "    upscaled = upscale_image(cropped, 4)\n",
    "\n",
    "    img.save(\"./.run/is_finished.png\")\n",
    "    cropped.save(\"./.run/is_finished_cropped.png\")\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images: a screenshot of a desktop UI, and a cropped 200x200 image of the current mouse location. \n",
    "    Your goal is to navigate to '{target.description}' located in '{target.location}' with the purpose of '{target.purpose}'. The screen size is {img.size} and the current coordinates are {coords}. \n",
    "    Please tell me if we have achieved that goal. Please return your response as a JSON object which conforms to the schema {CheckGoal.model_json_schema()}.\n",
    "    Please return raw json. If the goal is achieved the cursor should be directly over the target and should be a pointer, then return {{\"done\": true}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), upscaled]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=CheckGoal)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed.done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Likely Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from typing import List\n",
    "\n",
    "\n",
    "\n",
    "class BBox(BaseModel):\n",
    "    x: int\n",
    "    y: int\n",
    "    w: int\n",
    "    h: int\n",
    "\n",
    "class Coordinate(BaseModel):\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "\n",
    "def get_likely_targets(desktop: Desktop) -> List[Coordinate]:\n",
    "    pytesseract.pytesseract.tesseract_cmd = \"/opt/homebrew/bin/tesseract\"\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "    data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DATAFRAME)\n",
    "    filtered_data = data[(data.conf > 60) & (data.text.notna()) & (data.text != '')]\n",
    "\n",
    "    out = []\n",
    "    \n",
    "    for index, row in filtered_data.iterrows():\n",
    "        (x, y, w, h) = (row['left'], row['top'], row['width'], row['height'])\n",
    "        center_x = int(x + w / 2)\n",
    "        center_y = int(y + h / 2)\n",
    "        out.append(Coordinate(x=center_x, y=center_y))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_likely_targets(desktop)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.open_url(\"https://airbnb.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = b64_to_image(desktop.take_screenshot())\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = desktop.mouse_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img = crop_box_around(img, coords[0], coords[1], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def study(url: str, parallel: int = 4):\n",
    "    pool: List[Desktop] = []\n",
    "\n",
    "    for i in range(parallel):\n",
    "        desktop = Desktop.gce()\n",
    "        pool.append(desktop)\n",
    "\n",
    "    for desktop in pool:\n",
    "        desktop.open_url(url)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CurrentURL(BaseModel):\n",
    "    url: str = Field(..., description=\"The URL to navigate to\")\n",
    "\n",
    "def current_url(desktop: Desktop) -> str:\n",
    "    \"\"\"Find the current URL of the browser\"\"\"\n",
    "    \n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with a screenshot of a desktop UI, please return the current url of the browser.\n",
    "    Please return your response as a JSON object which conforms to the schema {CurrentURL.model_json_schema()}.\n",
    "    Please return raw json. If the current URL is https://airbnb.com, then return {{\"url\": \"https://airbnb.com\"}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=CurrentURL)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets(desktop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = targets.targets[1]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.open_url(\"https://google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger(\"mllm.router\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.DEBUG)  # Ensuring the handler captures debug logs\n",
    "\n",
    "# Optionally add a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(stdout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.mouse_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.move_mouse(x=500, y=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 10\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "shutil.rmtree(\"./.run\")\n",
    "os.makedirs(\"./.run\")\n",
    "\n",
    "class Example(BaseModel):\n",
    "    target: ClickTarget\n",
    "    before_img: str\n",
    "    after_img: str\n",
    "    click_coordinate: Tuple[int, int]\n",
    "\n",
    "completed_targets: List[ClickTarget] = []\n",
    "\n",
    "print(\"running agent with target: \", target.model_dump())\n",
    "\n",
    "for step in range(max_steps):\n",
    "    print(\"\\n---- checking if task is finished...\")\n",
    "    cursor_type = det_cursor_type(desktop)\n",
    "\n",
    "    print(\"cursor type: \", cursor_type.type)\n",
    "    if cursor_type.type != \"default\":\n",
    "        if is_finished(desktop, target):\n",
    "            print(\"task is done\")\n",
    "            completed_targets.append(target)\n",
    "            break\n",
    "\n",
    "        print(\"task is not finished but cursor is not default\")\n",
    "        extra_target = describe_location(desktop)\n",
    "        completed_targets.append(extra_target)\n",
    "        print(\"created extra target: \", extra_target.model_dump())\n",
    "\n",
    "        \n",
    "    print(\"\\n---- step: \", step)\n",
    "    direct = get_move_direction(desktop, target)\n",
    "\n",
    "    print(\"\\n---- move direction: \", direct.model_dump())\n",
    "\n",
    "    new_screen, new_cursor = apply_move(desktop, direct)\n",
    "    new_screen.save(\"./.run/step_\" + str(step) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study (Again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 10\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "from click import Option\n",
    "\n",
    "shutil.rmtree(\"./.run\")\n",
    "os.makedirs(\"./.run\")\n",
    "\n",
    "class ClickEvent(BaseModel):\n",
    "    target: ClickTarget\n",
    "    before_img: str\n",
    "    before_coordinate: Tuple[int, int]\n",
    "    after_img: str\n",
    "    click_coordinate: Tuple[int, int]\n",
    "    result: Optional[str] = None\n",
    "\n",
    "def click_target(target: ClickTarget, desktop: Desktop, max_steps: int = 10) -> List[ClickEvent]:\n",
    "\n",
    "    print(\"running agent with target: \", target.model_dump())\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        print(\"\\n---- checking if task is finished...\")\n",
    "        cursor_type = det_cursor_type(desktop)\n",
    "\n",
    "        print(\"cursor type: \", cursor_type.type)\n",
    "        if cursor_type.type != \"default\":\n",
    "            if is_finished(desktop, target):\n",
    "                print(\"task is done\")\n",
    "                completed_targets.append(target)\n",
    "                return\n",
    "\n",
    "            print(\"task is not finished but cursor is not default\")\n",
    "            extra_target = describe_location(desktop)\n",
    "            completed_targets.append(extra_target)\n",
    "            print(\"created extra target: \", extra_target.model_dump())\n",
    "\n",
    "            \n",
    "        print(\"\\n---- step: \", step)\n",
    "        direct = get_move_direction(desktop, target)\n",
    "\n",
    "        print(\"\\n---- move direction: \", direct.model_dump())\n",
    "\n",
    "        new_screen, new_cursor = apply_move(desktop, direct)\n",
    "        new_screen.save(\"./.run/step_\" + str(step) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserFlow(BaseModel):\n",
    "    \"\"\"e.g. A user should be able to search for a room in a city\"\"\"\n",
    "    # Is this just a task? or is there something more to it? its more generic, tasks are created from this\n",
    "    # How do we define variations?\n",
    "    pass\n",
    "\n",
    "\n",
    "class Expectation(BaseModel):\n",
    "    \"\"\"e.g. When I click this button, I expect a login screen to appear \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class TestPlan(BaseModel):\n",
    "    \"\"\"e.g. A test plan is a collection of test cases\"\"\"\n",
    "    uri: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# with open(\"./path/to/my/image.jpg\", 'rb') as file:\n",
    "#   data = base64.b64encode(file.read()).decode('utf-8')\n",
    "#   image = f\"data:application/octet-stream;base64,{data}\"\n",
    "\n",
    "\n",
    "# input = {\n",
    "#     \"image\": image,\n",
    "#     \"scale\": 2,\n",
    "#     \"face_enhance\": False\n",
    "# }\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:58306/predictions\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"version\": \"350d32041630ffbe63c8352783a26d94126809164e54085352f8326e53999085\",\n",
    "    \"input\": {\n",
    "        \"image\": \"https://replicate.delivery/pbxt/Ing7Fa4YMk6YtcoG1YZnaK3UwbgDB5guRc5M2dEjV6ODNLMl/cat.jpg\",\n",
    "        \"scale\": 2,\n",
    "        \"face_enhance\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "* Indexing on the pointer is useful to find targets, but not as useful for selecting them. The pointer is fairly reliable for web pages but the browser navigation buttons and tabs do not change the cursor image. There are other paths to validate the cursor location such as predicting the outcome of clicking the button, taking the action and then having the LLM judge if the button has been clicked\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
