{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentdesk import Desktop\n",
    "from agentdesk.device import ProvisionConfig\n",
    "from agentdesk.server.models import V1ProviderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProvisionConfig(provider=V1ProviderData(type=\"gce\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "\n",
      "successfully created desktop 'surfninja'\n",
      "starting proxy to vm...\n",
      "proxy from local port 8000 to remote port 8000 started...\n",
      "connected to desktop via agentd\n"
     ]
    }
   ],
   "source": [
    "desktop = Desktop.ensure(\"surfninja\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "waiting for desktop to be ready...\n",
      "\n",
      "successfully created desktop 'gracious-cray'\n",
      "starting proxy to vm...\n",
      "proxy from local port 8000 to remote port 8000 started...\n",
      "connected to desktop via agentd\n"
     ]
    }
   ],
   "source": [
    "desktop = Desktop.gce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_activity_ts': 1717189658,\n",
       " 'screen_size': {'x': 1280, 'y': 1024},\n",
       " 'os_info': 'Linux 6.5.0-1016-gcp',\n",
       " 'code_version': 'fb21fa020ff6f3d3f5f81c2db5bffd66a82ea86c'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desktop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desktop.mouse_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.move_mouse(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desktop.mouse_coordinates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Location\n",
    "\n",
    "Describe the current location of the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-31 16:09:00,228 - mllm.router - INFO - loading models with preference: dict_keys(['gpt-4o', 'gpt-4-turbo', 'anthropic/claude-3-opus-20240229', 'gemini/gemini-pro-vision'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-31 16:09:00,232 - mllm.router - INFO - Found LLM provider 'gpt-4o' API key in environment variables.\n",
      "2024-05-31 16:09:00,232 - mllm.router - INFO - Found LLM provider 'gpt-4-turbo' API key in environment variables.\n",
      "2024-05-31 16:09:00,233 - mllm.router - INFO - Found LLM provider 'anthropic/claude-3-opus-20240229' API key in environment variables.\n",
      "2024-05-31 16:09:00,234 - mllm.router - INFO - Found LLM provider 'gemini/gemini-pro-vision' API key in environment variables.\n",
      "Intialized router with Routing strategy: simple-shuffle\n",
      "\n",
      "Routing fallbacks: [{'gpt-4o': ['gpt-4-turbo', 'anthropic/claude-3-opus-20240229', 'gemini/gemini-pro-vision']}, {'gpt-4-turbo': ['anthropic/claude-3-opus-20240229', 'gemini/gemini-pro-vision']}, {'anthropic/claude-3-opus-20240229': ['gemini/gemini-pro-vision']}]\n",
      "\n",
      "Routing context window fallbacks: None\n",
      "\n",
      "Router Redis Caching=None\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from mllm import Router, RoleThread\n",
    "\n",
    "router = Router.from_env()\n",
    "\n",
    "class ClickArea(BaseModel):\n",
    "    is_clickable: bool = Field(description=\"Whether the area is clickable\")\n",
    "    description: str = Field(description=\"Description of what the mouse cursor is over\")\n",
    "    location: str = Field(description=\"General location of the mouse cursor relative to the full screen, e.g. top left, bottom right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surfninja.img import b64_to_image, image_to_b64, crop_box_around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_activity_ts': 1717189676,\n",
       " 'screen_size': {'x': 1280, 'y': 1024},\n",
       " 'os_info': 'Linux 6.5.0-1016-gcp',\n",
       " 'code_version': 'fb21fa020ff6f3d3f5f81c2db5bffd66a82ea86c'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desktop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_location(desktop: Desktop) -> ClickArea:\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I'm going to provide you with two images. The first is a picture of a desktop UI, \n",
    "    the second is a cropped portion of the first image containing just a 100x100 portion focusing on where the mouse cursor is.\n",
    "    Please describe what the mouse cursor as a JSON object conforming to the schema {ClickArea.model_json_schema()}.\n",
    "    Please return just raw json. For example if you see the mouse above the chromium icon then \n",
    "    you would return {{\"is_clickable\": true, \"description\": \"A blue chromium icon with the text 'chromium' beneath it\", \"location\": \"top-right\"}}.\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(cropped)],\n",
    "    )\n",
    "\n",
    "    resp = router.chat(thread, expect=ClickArea)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Targets\n",
    "\n",
    "Identify all possible clickable targets on a screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Target(BaseModel):\n",
    "    description: str = Field(description=\"A long description of the target e.g. A round blue button with the text 'login'\")\n",
    "    location: str = Field(description=\"A general location of the target e.g. top-right, center, bottom-left\")\n",
    "    purpose: str = Field(description=\"A general purpose of the target e.g. login, logout, register\")\n",
    "\n",
    "class Targets(BaseModel):\n",
    "    targets: List[Target] = Field(description=\"A list of targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(desktop: Desktop) -> Targets:\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with an image of a desktop UI. Please describe all the possible targets that you can interact with.\n",
    "    Please return a JSON object that conforms to the schema {Targets.model_json_schema()}.\n",
    "    Please be exhaustive, describing all possibilities on the screenshot.\n",
    "    Please return just raw json. For example {{\"targets\": [{{\"description\": \"A green button resembling a user\", \"location\": \"top-left\", \"purpose\": \"open user settings\"}}]}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=Targets)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to Targets\n",
    "Navigate to a target description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveDirection(BaseModel):\n",
    "    x: int = Field(description=\"Amount to move in the x direction. Positive values move right, negative values move left. 1 is equal to 1 pixel.\")\n",
    "    y: int = Field(description=\"Amount to move in the y direction. Positive values move down, negative values move up. 1 is equal to 1 pixel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_move_direction(desktop: Desktop, target: Target) -> MoveDirection:\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images: a screenshot of a desktop UI, and a cropped 100x100 image of the current mouse location. \n",
    "    Your goal is to navigate to '{target.description}' located in '{target.location}'. The screen size is {img.size} and the current coordinates are {coords}. \n",
    "    Please tell me which direction to move the mouse to get there. Please return a JSON object which conforms to the schema {MoveDirection.model_json_schema()}.\n",
    "    Please return raw json. For example, if I want to move 12 pixels to the left, and 3 pixels up, I would return: {{ \"x\": -12, \"y\": 3}}. You must move the mouse, \n",
    "    either 'x' or 'y' must be non-zero. The very tip of the cursor must be on your desired target, if unsure, move the mouse slightly.\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(cropped)]\n",
    "    )\n",
    "    img.save(\"./.run/screenshot_move.png\")\n",
    "    cropped.save(\"./.run/cropped_move.png\")\n",
    "    resp = router.chat(thread, expect=MoveDirection)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "\n",
    "def apply_move(desktop: Desktop, direction: MoveDirection) -> Tuple[Image.Image, Image.Image]:\n",
    "    current_coords = desktop.mouse_coordinates()\n",
    "    print(\"current_cords: \", current_coords)\n",
    "\n",
    "    # Calculate new absolute mouse coordinates\n",
    "    new_x = current_coords[0] + direction.x\n",
    "    new_y = current_coords[1] + direction.y\n",
    "\n",
    "    print(\"new: \", new_x, new_y)\n",
    "\n",
    "    # Move the mouse to the new coordinates\n",
    "    desktop.move_mouse(x=new_x, y=new_y)\n",
    "\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "    print(\"new_coords: \", coords)\n",
    "\n",
    "    return img, cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CursorType(BaseModel):\n",
    "    type: str = Field(description=\"Can be 'default', 'text', or 'pointer'\")\n",
    "\n",
    "\n",
    "def det_cursor_type(desktop: Desktop) -> CursorType:\n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1], padding=30)\n",
    "\n",
    "    cropped.save(\"./.run/cursor.png\")\n",
    "\n",
    "    composite = Image.open(\"./assets/cursor_composite_image.jpg\")\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images; first is an image of a mouse cursor and the second is an image \n",
    "        displaying the different types of cursors and their names. Please return what type of cursor you see.\n",
    "        Please return a json object which conforms to the schema {CursorType.model_json_schema()}.\n",
    "        Please return just raw json. For example if the cursor looks like a standard pointer return {{\"type\": \"default\"}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(cropped), image_to_b64(composite)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=CursorType)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed\n",
    "\n",
    "\n",
    "class CheckGoal(BaseModel):\n",
    "    done: bool = Field(description=\"Whether the cursor is over the correct location\")\n",
    "\n",
    "\n",
    "def is_finished(desktop: Desktop, target: Target) -> bool:\n",
    "    \n",
    "    thread = RoleThread()\n",
    "    b64_img = desktop.take_screenshot()\n",
    "    img = b64_to_image(b64_img)\n",
    "\n",
    "    coords = desktop.mouse_coordinates()\n",
    "    cropped = crop_box_around(img, coords[0], coords[1])\n",
    "\n",
    "\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=f\"\"\"I've provided you with two images: a screenshot of a desktop UI, and a cropped 100x100 image of the current mouse location. \n",
    "    Your goal is to navigate to '{target.description}' located in '{target.location}'. The screen size is {img.size} and the current coordinates are {coords}. \n",
    "    Please tell me if we have achieved that goal. Please return your response as a JSON object which conforms to the schema {CheckGoal.model_json_schema()}.\n",
    "    Please return raw json. If the goal is achieved the cursor should be directly over the target and should be a pointer, then return {{\"done\": true}}\n",
    "    \"\"\",\n",
    "        images=[image_to_b64(img), image_to_b64(cropped)]\n",
    "    )\n",
    "    resp = router.chat(thread, expect=CheckGoal)\n",
    "\n",
    "    if not resp.parsed:\n",
    "        raise ValueError(\"No click area found\")\n",
    "\n",
    "    return resp.parsed.done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-31 15:46:04,676 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4MJ2CBXZtNLh2jianAevVVxiXfM', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"targets\": [\\n    {\\n      \"description\": \"A round red circle with a white slash inside, located next to two arrow icons.\",\\n      \"location\": \"top-left\",\\n      \"purpose\": \"open Google homepage\"\\n    },\\n    {\\n      \"description\": \"A lock icon in the address bar\",\\n      \"location\": \"top-middle\",\\n      \"purpose\": \"indicates secure connection\"\\n    },\\n    {\\n      \"description\": \"A reload button that looks like a circular arrow\",\\n      \"location\": \"top-left\",\\n      \"purpose\": \"reload the webpage\"\\n    },\\n    {\\n      \"description\": \"A star icon next to the address bar\",\\n      \"location\": \"top-middle\",\\n      \"purpose\": \"bookmark the page\"\\n    },\\n    {\\n      \"description\": \"A dropdown menu with options for Gmail, Images, and other Google services\",\\n      \"location\": \"top-right\",\\n      \"purpose\": \"access Google services\"\\n    },\\n    {\\n      \"description\": \"A blue button with the text \\'Sign in\\'\",\\n      \"location\": \"top-right\",\\n      \"purpose\": \"sign in to Google account\"\\n    },\\n    {\\n      \"description\": \"A blue button with \\'Sign in\\' text in a popup dialog\",\\n      \"location\": \"middle-right\",\\n      \"purpose\": \"sign in to Google account\"\\n    },\\n    {\\n      \"description\": \"A \\'Stay signed out\\' link in the popup dialog\",\\n      \"location\": \"middle-right\",\\n      \"purpose\": \"stay signed out of Google account\"\\n    },\\n    {\\n      \"description\": \"A round Google logo with blue, red, yellow, and green colors\",\\n      \"location\": \"center\",\\n      \"purpose\": \"Google homepage logo\"\\n    },\\n    {\\n      \"description\": \"A search bar with a microphone icon\",\\n      \"location\": \"center\",\\n      \"purpose\": \"enter search queries\"\\n    },\\n    {\\n      \"description\": \"A square icon consisting of nine smaller squares\",\\n      \"location\": \"top-right\",\\n      \"purpose\": \"open Google apps\"\\n    },\\n    {\\n      \"description\": \"A grey button with \\'Google Search\\' text\",\\n      \"location\": \"center\",\\n      \"purpose\": \"initiate a Google search\"\\n    },\\n    {\\n      \"description\": \"A grey button with \\'I\\'m Feeling Lucky\\' text\",\\n      \"location\": \"center\",\\n      \"purpose\": \"take user to the top result of the search instantly\"\\n    },\\n    {\\n      \"description\": \"Links to About and Store\",\\n      \"location\": \"top-left\",\\n      \"purpose\": \"navigate to About and Store pages\"\\n    },\\n    {\\n      \"description\": \"Links to Advertising, Business, and How Search works\",\\n      \"location\": \"bottom-left\",\\n      \"purpose\": \"access related pages\"\\n    },\\n    {\\n      \"description\": \"Links to Privacy, Terms, and Settings\",\\n      \"location\": \"bottom-right\",\\n      \"purpose\": \"access related pages\"\\n    },\\n    {\\n      \"description\": \"A small green leaf icon with a text\",\\n      \"location\": \"bottom-center\",\\n      \"purpose\": \"information about climate action\"\\n    }\\n  ]\\n}', role='assistant'))], 'created': 1717191951, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 15111.569}\n"
     ]
    }
   ],
   "source": [
    "targets = get_targets(desktop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = targets.targets[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target(description=\"A grey button with 'I'm Feeling Lucky' text\", location='center', purpose='take user to the top result of the search instantly')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop.open_url(\"https://google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger(\"mllm.router\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.DEBUG)  # Ensuring the handler captures debug logs\n",
    "\n",
    "# Optionally add a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(stdout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:19:50,387 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tClV58yXhWC3BnOJdXKNSGZWrz', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\"type\": \"default\"}', role='assistant'))], 'created': 1717193990, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1394.381}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  0\n",
      "2024-05-31 16:19:53,903 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tExNYa8SYzpnExEttqYgUVbJNa', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='Based on the provided images and the coordinates, the mouse cursor is already located directly on the \"I\\'m Feeling Lucky\" button.\\n\\nTherefore, no movement is necessary. However, if slight adjustments are still desired for accuracy, here\\'s the JSON response indicating no movement:\\n\\n```json\\n{\\n  \"x\": 0,\\n  \"y\": 0\\n}\\n```', role='assistant'))], 'created': 1717193992, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 3011.161}\n",
      "\n",
      "---- move direction:  {'x': 0, 'y': 0}\n",
      "current_cords:  (745, 542)\n",
      "new:  745 542\n",
      "new_coords:  (745, 542)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:19:57,028 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tImT6gpQmCYJbZ5Xjj5PPpJSPn', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"default\"\\n}', role='assistant'))], 'created': 1717193996, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1201.528}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  1\n",
      "2024-05-31 16:20:00,799 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tKSnS1MYwNsoBsOCMNjPcNZdvW', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='To position the cursor over the \"I\\'m Feeling Lucky\" button, the new coordinates should exactly match the target button\\'s location.\\n\\nFrom the provided cropped 100x100 image, we see the cursor is on the right half of the \"I\\'m Feeling Lucky\" button, somewhat near the center. We can assume minor adjustments in the x and y directions might be suitable. \\n\\nSince the current coordinates are (745, 542), here is the calculated direction to navigate:\\n\\n```json\\n{\\n  \"x\": 2,\\n  \"y\": 0\\n}\\n```', role='assistant'))], 'created': 1717193998, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 3351.274}\n",
      "\n",
      "---- move direction:  {'x': 2, 'y': 0}\n",
      "current_cords:  (745, 542)\n",
      "new:  747 542\n",
      "new_coords:  (747, 542)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:04,008 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tP9tC85iqGBdbSFpyGUtsdxdOz', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"default\"\\n}', role='assistant'))], 'created': 1717194003, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1241.862}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  2\n",
      "2024-05-31 16:20:06,449 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tRIia2cLxr6vFX5X42taDQhovu', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"x\": 1,\\n  \"y\": 0\\n}', role='assistant'))], 'created': 1717194005, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2014.44}\n",
      "\n",
      "---- move direction:  {'x': 1, 'y': 0}\n",
      "current_cords:  (747, 542)\n",
      "new:  748 542\n",
      "new_coords:  (748, 542)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:09,725 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tVRZoCiA6jktUH9PbbR8yDT8JO', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\"type\": \"default\"}', role='assistant'))], 'created': 1717194009, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1344.675}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  3\n",
      "2024-05-31 16:20:12,610 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tX6aLjUF6gwtBjfGLhWj6ajktQ', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='The current mouse location seems to already be on the \"I\\'m Feeling Lucky\" button, based on the cropped image provided and the coordinates (748, 542). Therefore, no movement is necessary.\\n\\nHere is the JSON object indicating no movement:\\n\\n```json\\n{\\n  \"x\": 0,\\n  \"y\": 0\\n}\\n```', role='assistant'))], 'created': 1717194011, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2457.757}\n",
      "\n",
      "---- move direction:  {'x': 0, 'y': 0}\n",
      "current_cords:  (748, 542)\n",
      "new:  748 542\n",
      "new_coords:  (748, 542)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:17,324 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tcBOBkccQlIK76WomGxYeGbgRC', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"default\"\\n}', role='assistant'))], 'created': 1717194016, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2753.762}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  4\n",
      "2024-05-31 16:20:20,833 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tfW6DPHRBShINoliEDFBNXODoB', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='According to the provided image, the mouse is already hovering over the \\'I\\'m Feeling Lucky\\' button in the center. Therefore, there is no need to move the mouse.\\n\\nHere is the JSON object:\\n\\n```json\\n{\\n  \"x\": 0,\\n  \"y\": 0\\n}\\n```', role='assistant'))], 'created': 1717194019, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 3076.1189999999997}\n",
      "\n",
      "---- move direction:  {'x': 0, 'y': 0}\n",
      "current_cords:  (748, 542)\n",
      "new:  748 542\n",
      "new_coords:  (748, 542)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:24,301 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tjs7x5IPZAXVjte7yOGe7Q91mB', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"default\"\\n}', role='assistant'))], 'created': 1717194023, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1445.478}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  5\n",
      "2024-05-31 16:20:27,177 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tmZjsF9BiwueIE9PUHKlhNdhAN', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='Based on the provided images and information, it appears that the mouse cursor is already on the \"I\\'m Feeling Lucky\" button. Hence, no movement is necessary.\\n\\nHowever, if a slight adjustment is needed for precision, we can make minimal changes to ensure the tip of the cursor is centered on the button.\\n\\n```json\\n{\\n  \"x\": 0,\\n  \"y\": 0\\n}\\n```', role='assistant'))], 'created': 1717194026, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2457.261}\n",
      "\n",
      "---- move direction:  {'x': 0, 'y': 0}\n",
      "current_cords:  (748, 542)\n",
      "new:  748 542\n",
      "new_coords:  (748, 542)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:30,333 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tq6ZSiiLSFTQkVKax24LfZBC2C', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"default\"\\n}', role='assistant'))], 'created': 1717194030, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1218.501}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  6\n",
      "2024-05-31 16:20:33,516 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4ts7U86LEfeSFR9YryAM3cXbSNL', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='You are already on the \"I\\'m Feeling Lucky\" button, so no movement is necessary. However, if you need precise positioning advice, I suggest moving slightly in one direction to ensure the cursor is centered exactly on the button.\\n\\n```json\\n{\\n  \"x\": 0,\\n  \"y\": 0\\n}\\n```', role='assistant'))], 'created': 1717194032, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2644.2709999999997}\n",
      "\n",
      "---- move direction:  {'x': 0, 'y': 0}\n",
      "current_cords:  (748, 542)\n",
      "new:  748 542\n",
      "new_coords:  (748, 542)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:37,166 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4twnsL2teSd6YVzV5r44KGTaClo', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"default\"\\n}', role='assistant'))], 'created': 1717194036, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1747.767}\n",
      "cursor type:  default\n",
      "\n",
      "---- step:  7\n",
      "2024-05-31 16:20:39,907 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4tz97j6cHQ8CffFeqXPkakJjAwA', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"x\": 0,\\n  \"y\": 20\\n}', role='assistant'))], 'created': 1717194039, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2316.976}\n",
      "\n",
      "---- move direction:  {'x': 0, 'y': 20}\n",
      "current_cords:  (748, 542)\n",
      "new:  748 562\n",
      "new_coords:  (748, 562)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:43,573 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4u2YHQOubz4lVv2mrFWbNljgO76', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"pointer\"\\n}', role='assistant'))], 'created': 1717194042, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1748.3580000000002}\n",
      "cursor type:  pointer\n",
      "2024-05-31 16:20:46,551 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4u52isc3vyloK5NJcg1B3Inh3u6', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='Based on the provided images, the cursor is currently located over the button labeled \"I\\'m Feeling Hungry,\" instead of the desired \"I\\'m Feeling Lucky\" button in the center. Therefore, the goal is not achieved.\\n\\n```json\\n{\\n  \"done\": false\\n}\\n```', role='assistant'))], 'created': 1717194045, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2554.085}\n",
      "task is not finished but cursor is not default\n",
      "\n",
      "---- step:  8\n",
      "2024-05-31 16:20:51,263 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4u8rCZfXncSF0gPDMUdgeQZrEEq', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='Based on the provided images and the current coordinates (748, 562), the goal is to move the mouse pointer to the \\'I\\'m Feeling Lucky\\' button which is slightly to the left of the current mouse position.\\n\\nHere\\'s the JSON object with the needed directions to move the mouse:\\n\\n```json\\n{\\n  \"x\": -77,\\n  \"y\": 0\\n}\\n```', role='assistant'))], 'created': 1717194048, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 4290.293000000001}\n",
      "\n",
      "---- move direction:  {'x': -77, 'y': 0}\n",
      "current_cords:  (748, 562)\n",
      "new:  671 562\n",
      "new_coords:  (671, 562)\n",
      "\n",
      "---- checking if task is finished...\n",
      "2024-05-31 16:20:54,701 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4uEfxwH9vHXoP69vNjoVgF6ih9d', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"type\": \"pointer\"\\n}', role='assistant'))], 'created': 1717194054, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1411.467}\n",
      "cursor type:  pointer\n",
      "2024-05-31 16:20:57,172 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4uGFG6U4ZMVgweWd2RiWhAavc4Z', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='```\\n{\\n  \"done\": true\\n}\\n```', role='assistant'))], 'created': 1717194056, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 2104.247}\n",
      "2024-05-31 16:20:57,172 - mllm.router - ERROR - Validation error: Expecting value: line 1 column 1 (char 0) for '```\n",
      "{\n",
      "  \"done\": true\n",
      "}\n",
      "```\n",
      "2024-05-31 16:20:57,174 - mllm.router - ERROR - Retrying mllm.router.Router.chat.<locals>.call_llm in 0.0 seconds as it raised JSONDecodeError: Expecting value: line 1 column 1 (char 0).\n",
      "2024-05-31 16:20:59,000 - mllm.router - DEBUG - llm response: {'id': 'chatcmpl-9V4uI6LPrt1ut8McpIm5RCEmV0nZt', 'choices': [Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"done\": true\\n}', role='assistant'))], 'created': 1717194058, 'model': 'gpt-4o-2024-05-13', 'object': 'chat.completion', 'system_fingerprint': 'fp_aa87380ac5', '_response_ms': 1824.383}\n",
      "task is done\n"
     ]
    }
   ],
   "source": [
    "max_steps = 10\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "shutil.rmtree(\"./.run\")\n",
    "os.makedirs(\"./.run\")\n",
    "\n",
    "for step in range(max_steps):\n",
    "    print(\"\\n---- checking if task is finished...\")\n",
    "    cursor_type = det_cursor_type(desktop)\n",
    "\n",
    "    print(\"cursor type: \", cursor_type.type)\n",
    "    if cursor_type.type != \"default\":\n",
    "        if is_finished(desktop, target):\n",
    "            print(\"task is done\")\n",
    "            break\n",
    "\n",
    "        print(\"task is not finished but cursor is not default\")\n",
    "\n",
    "        \n",
    "    print(\"\\n---- step: \", step)\n",
    "    direct = get_move_direction(desktop, target)\n",
    "\n",
    "    print(\"\\n---- move direction: \", direct.model_dump())\n",
    "\n",
    "    new_screen, new_cursor = apply_move(desktop, direct)\n",
    "    new_screen.save(\"./.run/step_\" + str(step) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
