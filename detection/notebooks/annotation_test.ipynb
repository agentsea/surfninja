{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from Google storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'processed_webui'\n",
    "source_blob_name = 'balanced_7k_processed_filtered.zip'\n",
    "destination_dir = '../downloads/filtered'\n",
    "destination_file_name = destination_dir + \"/balanced_7k_processed_filtered.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob balanced_7k_processed_filtered.zip downloaded to ../downloads/filtered/balanced_7k_processed_filtered.zip.\n"
     ]
    }
   ],
   "source": [
    "Path(destination_dir).mkdir(parents=True, exist_ok=True)\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(source_blob_name)\n",
    "blob.download_to_filename(destination_file_name)\n",
    "print(f\"Blob {source_blob_name} downloaded to {destination_file_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(destination_file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../downloads/filtered/balanced_7k_processed_filtered.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# remove the zip file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/surfninja/lib/python3.11/pathlib.py:1147\u001b[0m, in \u001b[0;36mPath.unlink\u001b[0;34m(self, missing_ok)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03mRemove this file or link.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_ok:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../downloads/filtered/balanced_7k_processed_filtered.zip'"
     ]
    }
   ],
   "source": [
    "# remove the zip file\n",
    "Path(destination_file_name).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986 sites\n",
      "68103 bounding boxes\n"
     ]
    }
   ],
   "source": [
    "sites = Path(destination_dir)\n",
    "print(f\"{len(list(sites.iterdir()))} sites\")\n",
    "sites_list = list(sites.iterdir())\n",
    "bb_list = []\n",
    "for site in sites_list:\n",
    "    bb_list.extend(list((site / \"bounding_boxes\").iterdir()))\n",
    "print(f\"{len(bb_list)} bounding boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 100 random bounding boxes\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "random_bb_list = random.sample(bb_list, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the images around the selected bounding boxes\n",
    "\n",
    "\n",
    "images_output = Path(\"../downloads/filtered/images\")\n",
    "images_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for bb in random_bb_list:\n",
    "    # read bb json data\n",
    "    with open(bb, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    site = bb.parent.parent\n",
    "    image = site / \"images\" / \"full-screenshot.webp\"\n",
    "    image = Image.open(image)\n",
    "    cropped_image = image.crop((data[\"bounding_box\"][\"x\"] - 10, data[\"bounding_box\"][\"y\"] - 10, data[\"bounding_box\"][\"x\"] + data[\"bounding_box\"][\"width\"] + 10, data[\"bounding_box\"][\"y\"] + data[\"bounding_box\"][\"height\"] + 10))\n",
    "    # save\n",
    "    cropped_image.save(images_output / f\"{bb.parent.parent.name}_{bb.stem}.jpeg\", format=\"JPEG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average size: (155, 48)\n"
     ]
    }
   ],
   "source": [
    "# get the average image size in images_output\n",
    "\n",
    "sizes = []\n",
    "for image in images_output.iterdir():\n",
    "    sizes.append(Image.open(image).size)\n",
    "\n",
    "average_size = tuple([int(sum(x) / len(sizes)) for x in zip(*sizes)])\n",
    "print(f\"Average size: {average_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OpenAI's [tokenizer](https://platform.openai.com/tokenizer) and [pricing info](https://openai.com/api/pricing/), we can make the following estimates:\n",
    "\n",
    "Assumptions:\n",
    "- prompt: \n",
    "\"\"\"\n",
    "Write a name, a short description, and a tag indicating which type of UI element this is (button, heading, link, label, text, image or iframe). Use the following JSON format:\n",
    "\n",
    "{\n",
    "  \"name\": $NAME,\n",
    "  \"description\": $DESCRIPTION,\n",
    "  \"tag\": $TAG\n",
    "}\n",
    "\n",
    "Return the JSON only. Do not enclose it in a code block.\n",
    "\"\"\"\n",
    "- model: gpt4o\n",
    "- Avg img size: (216, 53)\n",
    "\n",
    "Estimates:\n",
    "- 78 input tokens, 31 output tokens per request.\n",
    "- Cost per request:\n",
    "    - Input: 78*5/1000000 ~ 0.00039 USD\n",
    "    - Output: 31*15/1000000 ~ 0.000465 USD\n",
    "- Number of requests: ~100\n",
    "- Cost per image: 0.001275 USD\n",
    "- Total cost per request: 0.001275 + 0.00039 + 0.000465 = 0.00213 USD\n",
    "- Total cost: 0.00213 * 100 = 0.213 USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_annotations = Path(\"../downloads/filtered/openai_annotations\")\n",
    "openai_annotations.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mllm import Router, Prompt\n",
    "from threadmem import RoleThread\n",
    "from pydantic import BaseModel\n",
    "from PIL import Image, ImageDraw\n",
    "from agentdesk import Desktop\n",
    "from surfninja.img import b64_to_image, image_to_b64, crop_box_around\n",
    "import os\n",
    "import getpass\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = getpass.getpass(prompt='Enter OpenAI API key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intialized router with Routing strategy: simple-shuffle\n",
      "\n",
      "Routing fallbacks: None\n",
      "\n",
      "Routing context window fallbacks: None\n",
      "\n",
      "Router Redis Caching=None\n"
     ]
    }
   ],
   "source": [
    "router = Router(\n",
    "    preference=[\"gpt-4o\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    tag: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "  'description': {'title': 'Description', 'type': 'string'},\n",
       "  'tag': {'title': 'Tag', 'type': 'string'}},\n",
       " 'required': ['name', 'description', 'tag'],\n",
       " 'title': 'Annotation',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = Annotation.model_json_schema()\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a name, a short description, and a tag indicating which type of UI element this is (button, heading, link, label, text, image or iframe). Use the following JSON format:\\n\\n{{\\n  \"name\": $NAME,\\n  \"description\": $DESCRIPTION,\\n  \"tag\": $TAG\\n}}\\n\\nReturn the JSON only. Do not enclose it in a code block.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a name, a short description, and a tag indicating which type of UI element this is (button, heading, link, label, text, image or iframe). Use the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"name\": $NAME,\n",
    "  \"description\": $DESCRIPTION,\n",
    "  \"tag\": $TAG\n",
    "}}\n",
    "\n",
    "Return the JSON only. Do not enclose it in a code block.\"\"\"\n",
    "prompt = prompt_template\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in images_output.iterdir():\n",
    "    image = Image.open(img)\n",
    "    image_b64 = image_to_b64(image, image_format=\"JPEG\")\n",
    "    thread = RoleThread()\n",
    "    thread.post(\n",
    "        role=\"user\",\n",
    "        msg=prompt,\n",
    "        images=[image_b64],\n",
    "    )\n",
    "    response = router.chat(thread, expect=Annotation, retries=0)\n",
    "    with open(openai_annotations / f\"{img.stem}.json\", \"w\") as f:\n",
    "        json.dump(response.parsed.json(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took ~2.5 mins, so if scaled to 68k it should probably have to be parallelized. The good news is that we wouldn't need to run the GPU.\n",
    "\n",
    "Let's now visualize the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m draw\u001b[38;5;241m.\u001b[39mtext((data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m20\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m image\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPress Enter to continue to the next image...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/surfninja/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/surfninja/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for bb in random_bb_list:\n",
    "    # read bb json data\n",
    "    with open(bb, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    site = bb.parent.parent\n",
    "    image = site / \"images\" / \"full-screenshot.webp\"\n",
    "    image = Image.open(image)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"], data[\"bounding_box\"][\"x\"] + data[\"bounding_box\"][\"width\"], data[\"bounding_box\"][\"y\"] + data[\"bounding_box\"][\"height\"]), outline=\"red\")\n",
    "    # get annotation data\n",
    "    with open(openai_annotations / f\"{bb.parent.parent.name}_{bb.stem}.json\", \"r\") as f:\n",
    "        tag_data = json.load(f)\n",
    "        tag_data = json.loads(tag_data)\n",
    "    draw.text((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"] - 20), f\"{tag_data['name']} - {tag_data['tag']}\", fill=\"red\")\n",
    "    image.show()\n",
    "    input(\"Press Enter to continue to the next image...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the test images\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "output_zip_path = Path('../downloads/test_images.zip')\n",
    "base_output_path = Path(\"../downloads/filtered/images\")\n",
    "\n",
    "with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(base_output_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            zipf.write(file_path, os.path.relpath(file_path, base_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the openai annotations\n",
    "output_zip_path = Path('../downloads/openai_annotations.zip')\n",
    "base_output_path = Path(\"../downloads/filtered/openai_annotations\")\n",
    "\n",
    "with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(base_output_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            zipf.write(file_path, os.path.relpath(file_path, base_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../downloads/openai_annotations.zip uploaded to openai_annotations.zip.\n"
     ]
    }
   ],
   "source": [
    "# upload the openai annotations zip file to GCS\n",
    "from google.cloud import storage\n",
    "\n",
    "bucket_name = \"processed_webui\"\n",
    "source_file_name = \"../downloads/openai_annotations.zip\"\n",
    "destination_blob_name = \"openai_annotations.zip\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(source_file_name)\n",
    "print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../downloads/test_images.zip uploaded to test_images.zip.\n"
     ]
    }
   ],
   "source": [
    "# upload the test images zip file to GCS\n",
    "\n",
    "bucket_name = \"processed_webui\"\n",
    "source_file_name = \"../downloads/test_images.zip\"\n",
    "destination_blob_name = \"test_images.zip\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(source_file_name)\n",
    "print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PaliGemma annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test images from GCS\n",
    "bucket_name = 'processed_webui'\n",
    "source_blob_name = 'test_images.zip'\n",
    "destination_dir = '../downloads/filtered/images'\n",
    "destination_file_name = destination_dir + \"/test_images.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob test_images.zip downloaded to ../downloads/filtered/images/test_images.zip.\n"
     ]
    }
   ],
   "source": [
    "Path(destination_dir).mkdir(parents=True, exist_ok=True)\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(source_blob_name)\n",
    "blob.download_to_filename(destination_file_name)\n",
    "print(f\"Blob {source_blob_name} downloaded to {destination_file_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(destination_file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(destination_file_name).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path(destination_dir).iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paligemma_annotations = Path(\"../downloads/filtered/paligemma_annotations\")\n",
    "paligemma_annotations.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 24 01:27:50 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
      "| N/A   47C    P8              17W /  72W |    119MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA L4                      Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P8              12W /  72W |     13MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1494      G   /usr/lib/xorg/Xorg                           95MiB |\n",
      "|    0   N/A  N/A      1553      G   /usr/bin/gnome-shell                         10MiB |\n",
      "|    1   N/A  N/A      1494      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m850.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: filelock in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, transformers, bitsandbytes, accelerate\n",
      "Successfully installed accelerate-0.31.0 bitsandbytes-0.43.1 safetensors-0.4.3 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturo/miniconda3/envs/surfninja/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from PIL import Image\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(model_id, device, image_paths, prompt_type):\n",
    "    start = time.time()\n",
    "    model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=device,\n",
    "    ).eval()\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    \n",
    "    batch_size = 8\n",
    "    images = [Image.open(path) for path in image_paths]\n",
    "    prompts = [prompt_type] * len(images)\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_images = images[i:i + batch_size]\n",
    "        batch_prompts = prompts[i:i + batch_size]\n",
    "        model_inputs = processor(text=batch_prompts, images=batch_images, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            generations = model.generate(**model_inputs, max_new_tokens=100, do_sample=False)\n",
    "            predictions = processor.batch_decode(generations[:,model_inputs[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
    "        all_predictions.extend(predictions)\n",
    "    end = time.time()\n",
    "    print(f\"Time taken: {end - start:.2f} seconds\")\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_output = Path(\"../downloads/filtered/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 3/3 [02:09<00:00, 43.08s/it]\n",
      "Downloading shards: 100%|██████████| 3/3 [02:09<00:00, 43.10s/it]\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.51s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 231.79 seconds\n",
      "Time taken: 242.24 seconds\n"
     ]
    }
   ],
   "source": [
    "model_id = \"google/paligemma-3b-ft-widgetcap-448\"\n",
    "image_paths = list(images_output.iterdir())\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "    future_caption = executor.submit(process_images, model_id, \"cuda:0\", image_paths, \"caption\")\n",
    "    future_ocr = executor.submit(process_images, model_id, \"cuda:1\", image_paths, \"ocr\")\n",
    "\n",
    "    caption_predictions = future_caption.result()\n",
    "    ocr_predictions = future_ocr.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predictions\n",
    "assert len(caption_predictions) == len(ocr_predictions) == len(image_paths)\n",
    "for i in range(len(image_paths)):\n",
    "    with open(paligemma_annotations / f\"{image_paths[i].stem}.json\", \"w\") as f:\n",
    "        json.dump({\"name\": caption_predictions[i], \"ocr\": ocr_predictions[i]}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"text box\", \"ocr\": \"Creating your first Pod at C\"}{\"name\": \"text\", \"ocr\": \":\"}{\"name\": \"go to blog\", \"ocr\": \"Blog\"}{\"name\": \"logo\", \"ocr\": \"HATESONG.COM\"}{\"name\": \"zoom in\", \"ocr\": \"22-Feb-2020 03:04\\n4M\\n22-Feb-2020 03:04\\n4M\\nz\\n22-Feb-2020 03:04\\n4M\\nx7\"}{\"name\": \"zoom in\", \"ocr\": \"Q\"}{\"name\": \"pound\", \"ocr\": \"\\u00a31\"}{\"name\": \"open directory\", \"ocr\": \"Directory\"}{\"name\": \"error page\", \"ocr\": \"You don't have permission to access \\\"http://www.findycompany.com/company/ on this server.\"}{\"name\": \"click to view image\", \"ocr\": \"M\"}{\"name\": \"select text\", \"ocr\": \"r bh2010@johnthornhillmarketing.com\\nthem slatham@domainsrea.com\"}{\"name\": \"text box\", \"ocr\": \"Node.js v10.x\"}{\"name\": \"text in black and white\", \"ocr\": \"FRAN\\u00c7AIS\"}{\"name\": \"select feed\", \"ocr\": \"Feeds\"}{\"name\": \"select the task\", \"ocr\": \"tasks\"}{\"name\": \"text box\", \"ocr\": \"Everything on this site was made by ME unless stated otherwise.\"}{\"name\": \"logo\", \"ocr\": \"1. Paper Books\"}{\"name\": \"zoom in\", \"ocr\": \"Q\"}{\"name\": \"click to enlarge\", \"ocr\": \"Shcherbatyuk, Ole Antoniw, Hanna h Kozachenko Anna\"}{\"name\": \"view posts\", \"ocr\": \"POSTS\"}{\"name\": \"go to privacy shield\", \"ocr\": \"PRIVACY SHIELD\"}{\"name\": \"go to projects\", \"ocr\": \"Projects\"}{\"name\": \"go to next\", \"ocr\": \"100%\"}{\"name\": \"2 years ago by\", \"ocr\": \"2 years ago by\"}{\"name\": \"go to home\", \"ocr\": \"Home\"}{\"name\": \"light blue\", \"ocr\": \"30\"}{\"name\": \"alumni and giving\", \"ocr\": \"Alumni & Giving\"}{\"name\": \"scroll down\", \"ocr\": \"6\"}{\"name\": \"get started button\", \"ocr\": \"Get Started\"}{\"name\": \"blue light on black background\", \"ocr\": \"M\"}{\"name\": \"logo for food tv\", \"ocr\": \"Foodtv.us\"}{\"name\": \"logo\", \"ocr\": \"y Elmastudio\"}{\"name\": \"contact\", \"ocr\": \"Contact\"}{\"name\": \"text box\", \"ocr\": \"You are not permitted to access the requested URL\"}{\"name\": \"email a\", \"ocr\": \"Email: a\"}{\"name\": \"logo\", \"ocr\": \"Australia\"}{\"name\": \"logo\", \"ocr\": \"t Namecheap.com.\"}{\"name\": \"go to next\", \"ocr\": \"100%\"}{\"name\": \"click to view\", \"ocr\": \"Cosmetics and Makeup\"}{\"name\": \"proudly powered by wordpress\", \"ocr\": \"Proudly powered by WordPress\"}{\"name\": \"click to enlarge\", \"ocr\": \"what i eat\"}{\"name\": \"logo of the workgroup\", \"ocr\": \"Werkgemeenschap voor\\n$\\nInformatie- en\\nCommunicatietheorie\"}{\"name\": \"home\", \"ocr\": \"home\"}{\"name\": \"select the option\", \"ocr\": \"Shells and Spirals\"}{\"name\": \"contact\", \"ocr\": \"Contact\"}{\"name\": \"text box\", \"ocr\": \"431x precteno\"}{\"name\": \"icon of a document\", \"ocr\": \"\\u76ee\"}{\"name\": \"regional economic analysis\", \"ocr\": \"REGIONAL ECONOMIC ANALYSIS\"}{\"name\": \"text box\", \"ocr\": \"Representation\"}{\"name\": \"and\", \"ocr\": \"and\"}{\"name\": \"text box\", \"ocr\": \"Your Design Work, But More Awesome:\"}{\"name\": \"sample text\", \"ocr\": \"Uus ja senisest veel v\\u00f5imsam ja\\npaindlikum sisuhalduslahendus.\\nVeebilehtede haldamine ei pea olema\\nkeerukas.\"}{\"name\": \"download button\", \"ocr\": \"Download\"}{\"name\": \"black background\", \"ocr\": \"100\\n100\"}{\"name\": \"image of letter c\", \"ocr\": \"C\"}{\"name\": \"logo by matt laroche\", \"ocr\": \"by matt laroche\"}{\"name\": \"text page\", \"ocr\": \"A Titan URL uses extra parameters. Parameters are not query parameters! There is no question mark after the URL. Parameters are separated from the rest of the URL and each other using a semicolon and they come as key/value pairs. Here's what the URL says:\"}{\"name\": \"title image\", \"ocr\": \"How to Create a Guest ID\"}{\"name\": \"sample text\", \"ocr\": \"La Fondation a pour but destin\\u00e9e\\u00e9ss\\u00e9, \\u00e0 caract\\u00e8re philanthropique, philosophique,\\nscientifique, p\\u00e9dagogiqueque et culturel\"}{\"name\": \"text\", \"ocr\": \"m\"}{\"name\": \"euro\", \"ocr\": \"EUR\"}{\"name\": \"logo for the studio\", \"ocr\": \"Wierk Studio\"}{\"name\": \"go to facebook\", \"ocr\": \"f\"}{\"name\": \"download raw\", \"ocr\": \"[Download RAW m\"}{\"name\": \"logo\", \"ocr\": \"ut | N\"}{\"name\": \"logo for atelier analogue\", \"ocr\": \"Atelier Analogue\"}{\"name\": \"logo for the project\", \"ocr\": \"\\u2022 Invidious project\"}{\"name\": \"logo\", \"ocr\": \"Viktor\"}{\"name\": \"logo for museum studies\", \"ocr\": \"MUSEUM STUDIES\"}{\"name\": \"select font\", \"ocr\": \"e ad@jeremiahqing.com\\ntro@yiwylcnx.com\"}{\"name\": \"change font\", \"ocr\": \"Dean O'Tierney d Canimbe Woulfe\"}{\"name\": \"black color\", \"ocr\": \"100%\"}{\"name\": \"text box with text i 'm developing apps for\", \"ocr\": \"I'm developing Apps for\"}{\"name\": \"screen shot of text box\", \"ocr\": \"@romanzolotarev\"}{\"name\": \"text box\", \"ocr\": \"16 Jun, 2020\"}{\"name\": \"zoom in\", \"ocr\": \"w it. R\"}{\"name\": \"text in red\", \"ocr\": \"\\u6606\\u660e\\u5e02\"}{\"name\": \"text\", \"ocr\": \"\\u4f5c\\u8005:19\"}{\"name\": \"logo\", \"ocr\": \"shps hop\"}{\"name\": \"text\", \"ocr\": \"Spelk\"}{\"name\": \"click to enlarge\", \"ocr\": \"r transfer\\nfor free\"}{\"name\": \"blood bag\", \"ocr\": \"1\"}{\"name\": \"image of text\", \"ocr\": \"\\u7f51\\u7ad9\\u5206\\u7c7b\"}{\"name\": \"zoom in on text\", \"ocr\": \"I renew it nd build\"}{\"name\": \"image of text\", \"ocr\": \"auction. It this domains to D\"}{\"name\": \"product logo\", \"ocr\": \"\\u4ea7\\u54c1\\u5c55\\u793a\"}{\"name\": \"error or tr site for\", \"ocr\": \"er or tr site fo\"}{\"name\": \"text in chinese characters\", \"ocr\": \"\\u8d77\\u7f8e\\u5176\"}{\"name\": \"go to the website\", \"ocr\": \"\\u70ed\\u95e8\\u6392\\u884c\"}{\"name\": \"text image\", \"ocr\": \"\\u7537\\u5b50\\u8c08\\u4fe1\\u9ec4\\u725b\\u5750\\u4f1f\\u5927\\u5df4\\u62c9\\u6389\\u540c\\u673a\\u65b9\\u5411\"}{\"name\": \"logo of the company\", \"ocr\": \"\\u7b4b\\u6597\\u4e91\"}{\"name\": \"click to open\", \"ocr\": \"\\u4e95\\u4e0a\"}{\"name\": \"image of text\", \"ocr\": \"\\u00b7\\u5b66\\u8005:\\u57ce\\u533a\\u4eba\\u53e3\\u964d\\u4f4e\\u4e0d\\u4ee3\\u8868\\u57ce\\u5e02\\u6d3b\\u529b\"}{\"name\": \"zoom in\", \"ocr\": \"w it. R\"}{\"name\": \"go to website\", \"ocr\": \"gsliveglobal.com\"}{\"name\": \"text box\", \"ocr\": \"n. If this is your domain, you can still re\\naine to Dynarot com to save more and\"}{\"name\": \"select text\", \"ocr\": \"his is your doma o Dynadot.com t\"}{\"name\": \"text in chinese characters\", \"ocr\": \"\\u666f\\u5fb7\\u9547\\u5e02\"}{\"name\": \"text box\", \"ocr\": \"The domain has expired and may be available at a\"}{\"name\": \"zoom in\", \"ocr\": \"w it. R\"}"
     ]
    }
   ],
   "source": [
    "!cat ../downloads/filtered/paligemma_annotations/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the paligemma annotations\n",
    "import os\n",
    "output_zip_path = Path('../downloads/paligemma_annotations.zip')\n",
    "base_output_path = Path(\"../downloads/filtered/paligemma_annotations\")\n",
    "\n",
    "with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(base_output_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            zipf.write(file_path, os.path.relpath(file_path, base_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../downloads/paligemma_annotations.zip uploaded to paligemma_annotations.zip.\n"
     ]
    }
   ],
   "source": [
    "# upload the paligemma annotations zip file to GCS\n",
    "\n",
    "bucket_name = \"processed_webui\"\n",
    "source_file_name = \"../downloads/paligemma_annotations.zip\"\n",
    "destination_blob_name = \"paligemma_annotations.zip\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(source_file_name)\n",
    "print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing PaliGemma annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download paligemma annotations from GCS\n",
    "bucket_name = 'processed_webui'\n",
    "source_blob_name = 'paligemma_annotations.zip'\n",
    "destination_dir = '../downloads/filtered/paligemma_annotations'\n",
    "destination_file_name = destination_dir + \"/paligemma_annotations.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob paligemma_annotations.zip downloaded to ../downloads/filtered/paligemma_annotations/paligemma_annotations.zip.\n"
     ]
    }
   ],
   "source": [
    "Path(destination_dir).mkdir(parents=True, exist_ok=True)\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(source_blob_name)\n",
    "blob.download_to_filename(destination_file_name)\n",
    "print(f\"Blob {source_blob_name} downloaded to {destination_file_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(destination_file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(destination_file_name).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path(destination_dir).iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "paligemma_annotations = Path(\"../downloads/filtered/paligemma_annotations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m draw\u001b[38;5;241m.\u001b[39mtext((data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m20\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m image\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPress Enter to continue to the next image...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/surfninja/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/surfninja/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for bb in random_bb_list:\n",
    "    # read bb json data\n",
    "    with open(bb, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    site = bb.parent.parent\n",
    "    image = site / \"images\" / \"full-screenshot.webp\"\n",
    "    image = Image.open(image)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"], data[\"bounding_box\"][\"x\"] + data[\"bounding_box\"][\"width\"], data[\"bounding_box\"][\"y\"] + data[\"bounding_box\"][\"height\"]), outline=\"red\")\n",
    "    # get annotation data\n",
    "    with open(paligemma_annotations / f\"{bb.parent.parent.name}_{bb.stem}.json\", \"r\") as f:\n",
    "        tag_data = json.load(f)\n",
    "        # tag_data = json.loads(tag_data)\n",
    "    draw.text((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"] - 20), f\"{tag_data['name']} - {tag_data['ocr']}\", fill=\"red\")\n",
    "    image.show()\n",
    "    input(\"Press Enter to continue to the next image...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store random_bb_list in ../downloads/ with pickle\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../downloads/random_bb_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(random_bb_list, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_annotated_images = Path(\"../downloads/openai_annotated_images\")\n",
    "openai_annotated_images.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for bb in random_bb_list:\n",
    "    # read bb json data\n",
    "    with open(bb, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    site = bb.parent.parent\n",
    "    image = site / \"images\" / \"full-screenshot.webp\"\n",
    "    image = Image.open(image)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"], data[\"bounding_box\"][\"x\"] + data[\"bounding_box\"][\"width\"], data[\"bounding_box\"][\"y\"] + data[\"bounding_box\"][\"height\"]), outline=\"red\")\n",
    "    # get annotation data\n",
    "    with open(openai_annotations / f\"{bb.parent.parent.name}_{bb.stem}.json\", \"r\") as f:\n",
    "        tag_data = json.load(f)\n",
    "        tag_data = json.loads(tag_data)\n",
    "    draw.text((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"] - 20), f\"{tag_data['name']} - {tag_data['tag']}\", fill=\"red\")\n",
    "    # save image\n",
    "    image.save(openai_annotated_images / f\"{bb.parent.parent.name}_{bb.stem}.jpeg\", format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paligemma_annotated_images = Path(\"../downloads/paligemma_annotated_images\")\n",
    "paligemma_annotated_images.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for bb in random_bb_list:\n",
    "    # read bb json data\n",
    "    with open(bb, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    site = bb.parent.parent\n",
    "    image = site / \"images\" / \"full-screenshot.webp\"\n",
    "    image = Image.open(image)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"], data[\"bounding_box\"][\"x\"] + data[\"bounding_box\"][\"width\"], data[\"bounding_box\"][\"y\"] + data[\"bounding_box\"][\"height\"]), outline=\"red\")\n",
    "    # get annotation data\n",
    "    with open(paligemma_annotations / f\"{bb.parent.parent.name}_{bb.stem}.json\", \"r\") as f:\n",
    "        tag_data = json.load(f)\n",
    "    draw.text((data[\"bounding_box\"][\"x\"], data[\"bounding_box\"][\"y\"] - 20), f\"{tag_data['name']} - {tag_data['ocr']}\", fill=\"red\")\n",
    "    # save image\n",
    "    image.save(paligemma_annotated_images / f\"{bb.parent.parent.name}_{bb.stem}.jpeg\", format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PaliGemma annotation took in total 242 seconds to process the 100 images, using a batch-size of 8, and running the detection and ocr tasks in parallel.\n",
    "\n",
    "Using these same parameters, we would expect the annotation of the full dataset to take ~ 164560s (242 / 100 * 68k), which is roughly 45 hours. At $2 per compute-hour that's a total cost of $90 USD.\n",
    "\n",
    "This is lower than the estimated ~ $140 USD for doing it with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surfninja",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
